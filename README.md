# SPARTAN: Secure Privacy-Adaptive Reasoning with Test-time Attack Neutralization

[![CI/CD](https://github.com/hmshujaatzaheer/spartan-framework/actions/workflows/ci.yml/badge.svg)](https://github.com/hmshujaatzaheer/spartan-framework/actions/workflows/ci.yml)
[![codecov](https://codecov.io/gh/hmshujaatzaheer/spartan-framework/branch/main/graph/badge.svg)](https://codecov.io/gh/hmshujaatzaheer/spartan-framework)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

A unified framework for detecting and defending against mechanistic privacy attacks in Reasoning Large Language Models (LLMs).

## ğŸ¯ Overview

SPARTAN addresses a critical research gap: **reasoning LLMs' test-time compute (TTC) mechanisms create unique privacy attack surfaces that existing frameworks neither characterize nor defend against**.

Modern reasoning LLMs rely on:
- **Process Reward Models (PRMs)** for step-level verification
- **Self-Consistency Voting** for answer aggregation
- **Monte Carlo Tree Search (MCTS)** for exploration

These mechanisms introduce novel privacy vulnerabilities distinct from traditional inference attacks. SPARTAN provides:

1. **Attack Detection**: Mechanistic Privacy Leakage Quantification (MPLQ)
2. **Adaptive Defense**: Reasoning-Aware Adaptive Sanitization (RAAS)
3. **Optimization**: Reasoning-Privacy Pareto Optimization (RPPO)

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  User Query â”‚â”€â”€â”€â”€â–¶â”‚         Reasoning LLM            â”‚â”€â”€â”€â”€â–¶â”‚   Output    â”‚
â”‚      x      â”‚     â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚     â”‚     y       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”‚    TTC Components           â”‚ â”‚     â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                    â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”   â”‚ â”‚            â”‚
                    â”‚  â”‚  â”‚ PRM â”‚ â”‚Vote â”‚ â”‚MCTS â”‚   â”‚ â”‚            â”‚
                    â”‚  â”‚  â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜   â”‚ â”‚            â”‚
                    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚            â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
                                   â”‚                                â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
                    â”‚           MPLQ               â”‚                â”‚
                    â”‚    Attack Detection          â”‚â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â”‚  â€¢ PRM Leakage Analysis      â”‚     leakage
                    â”‚  â€¢ Vote Distribution         â”‚     signals
                    â”‚  â€¢ MCTS Value Analysis       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚ risk score
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚           RAAS               â”‚
                    â”‚    Adaptive Defense          â”‚
                    â”‚  â€¢ Feature-Selective Noise   â”‚
                    â”‚  â€¢ Vote Flattening           â”‚
                    â”‚  â€¢ Value Perturbation        â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚           RPPO               â”‚
                    â”‚    Pareto Optimization       â”‚
                    â”‚  â€¢ Multi-Objective Reward    â”‚
                    â”‚  â€¢ UCB Arm Selection         â”‚
                    â”‚  â€¢ Gradient Refinement       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                   â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚     Sanitized Output Å·       â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“¦ Installation

### From PyPI (recommended)

```bash
pip install spartan-framework
```

### From Source

```bash
git clone https://github.com/hmshujaatzaheer/spartan-framework.git
cd spartan-framework
pip install -e ".[dev]"
```

### Requirements

- Python 3.9+
- PyTorch 2.0+
- transformers 4.30+

## ğŸš€ Quick Start

### Basic Usage

```python
from spartan import SPARTAN
from spartan.models import MockReasoningLLM

# Initialize SPARTAN with a reasoning LLM
llm = MockReasoningLLM()
spartan = SPARTAN(llm)

# Process a query with privacy protection
query = "Solve: What is the integral of x^2 from 0 to 1?"
result = spartan.process(query)

print(f"Sanitized Output: {result.output}")
print(f"Privacy Risk Score: {result.risk_score:.4f}")
print(f"Defense Applied: {result.defense_applied}")
```

### Module-Level Usage

```python
from spartan.mplq import MPLQ
from spartan.raas import RAAS
from spartan.rppo import RPPO

# Initialize modules
mplq = MPLQ()
raas = RAAS()
rppo = RPPO()

# Step 1: Quantify privacy leakage
risk_analysis = mplq.analyze(query, reasoning_trace, prm_scores, vote_distribution)

# Step 2: Apply adaptive defense
sanitized = raas.sanitize(output, risk_analysis)

# Step 3: Optimize parameters
optimal_params = rppo.optimize(historical_data)
```

### Attack Simulation

```python
from spartan.attacks import NLBAAttack, SMVAAttack, MVNAAttack

# Natural Language Blindness Attack (targets PRM)
nlba = NLBAAttack()
nlba_result = nlba.execute(target_model, query)

# Single-Model Voting Attack (targets self-consistency)
smva = SMVAAttack()
smva_result = smva.execute(target_model, query, num_samples=10)

# MCTS Value Network Attack
mvna = MVNAAttack()
mvna_result = mvna.execute(target_model, query)
```

### Defense Configuration

```python
from spartan import SPARTAN
from spartan.config import SPARTANConfig

# Custom configuration
config = SPARTANConfig(
    # MPLQ settings
    prm_threshold=0.3,
    vote_threshold=0.4,
    mcts_threshold=0.5,
    
    # RAAS settings
    epsilon_min=0.01,
    epsilon_max=0.5,
    importance_weighting=True,
    
    # RPPO settings
    learning_rate=0.01,
    num_arms=10,
    ucb_exploration=2.0,
    
    # Objective weights
    accuracy_weight=0.4,
    privacy_weight=0.4,
    compute_weight=0.2,
)

spartan = SPARTAN(llm, config=config)
```

## ğŸ“Š Experimental Results

### Attack Effectiveness

| Attack Type | Target Mechanism | AUC-ROC | TPR@FPR=0.01 |
|-------------|------------------|---------|--------------|
| NLBA        | PRM              | 0.847   | 0.312        |
| SMVA        | Voting           | 0.793   | 0.267        |
| MVNA        | MCTS             | 0.821   | 0.289        |
| Combined    | All              | 0.891   | 0.378        |

### Defense Performance

| Defense Method     | Accuracy Retention | Attack Success Reduction |
|-------------------|-------------------|-------------------------|
| No Defense        | 100%              | 0%                      |
| Uniform DP        | 72.3%             | 45.2%                   |
| Feature DP        | 84.1%             | 52.8%                   |
| **SPARTAN (Ours)**| **91.2%**         | **67.4%**               |

## ğŸ”¬ Research Questions Addressed

1. **RQ1**: How do reasoning LLMs' TTC mechanisms create distinct privacy vulnerabilities compared to standard inference?

2. **RQ2**: Can mechanistic attacks achieve higher success rates than black-box MIAs by exploiting internal reasoning components?

3. **RQ3**: Does adaptive, risk-proportional defense outperform uniform protection in privacy-utility tradeoff?

4. **RQ4**: What is the computational overhead of SPARTAN and can it operate in real-time deployment?

## ğŸ“ Project Structure

```
spartan-framework/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ spartan/
â”‚       â”œâ”€â”€ __init__.py          # Main SPARTAN class
â”‚       â”œâ”€â”€ mplq/                # Mechanistic Privacy Leakage Quantification
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ analyzer.py      # Core MPLQ analyzer
â”‚       â”‚   â”œâ”€â”€ prm_leakage.py   # PRM-specific leakage detection
â”‚       â”‚   â”œâ”€â”€ vote_leakage.py  # Voting distribution analysis
â”‚       â”‚   â””â”€â”€ mcts_leakage.py  # MCTS value network analysis
â”‚       â”œâ”€â”€ raas/                # Reasoning-Aware Adaptive Sanitization
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ sanitizer.py     # Core RAAS sanitizer
â”‚       â”‚   â”œâ”€â”€ prm_defense.py   # PRM noise injection
â”‚       â”‚   â”œâ”€â”€ vote_defense.py  # Vote flattening
â”‚       â”‚   â””â”€â”€ mcts_defense.py  # Value perturbation
â”‚       â”œâ”€â”€ rppo/                # Reasoning-Privacy Pareto Optimization
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ optimizer.py     # Core RPPO optimizer
â”‚       â”‚   â”œâ”€â”€ bandit.py        # UCB bandit implementation
â”‚       â”‚   â””â”€â”€ pareto.py        # Pareto front utilities
â”‚       â”œâ”€â”€ attacks/             # Attack implementations
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ base.py          # Base attack class
â”‚       â”‚   â”œâ”€â”€ nlba.py          # Natural Language Blindness Attack
â”‚       â”‚   â”œâ”€â”€ smva.py          # Single-Model Voting Attack
â”‚       â”‚   â””â”€â”€ mvna.py          # MCTS Value Network Attack
â”‚       â”œâ”€â”€ models/              # Model interfaces
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ base.py          # Base LLM interface
â”‚       â”‚   â””â”€â”€ mock.py          # Mock implementations for testing
â”‚       â”œâ”€â”€ utils/               # Utilities
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ distributions.py # Statistical distributions
â”‚       â”‚   â”œâ”€â”€ metrics.py       # Evaluation metrics
â”‚       â”‚   â””â”€â”€ noise.py         # Noise generation
â”‚       â”œâ”€â”€ config.py            # Configuration classes
â”‚       â””â”€â”€ cli.py               # Command-line interface
â”œâ”€â”€ tests/                       # Comprehensive test suite
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_mplq.py
â”‚   â”œâ”€â”€ test_raas.py
â”‚   â”œâ”€â”€ test_rppo.py
â”‚   â”œâ”€â”€ test_attacks.py
â”‚   â”œâ”€â”€ test_integration.py
â”‚   â””â”€â”€ conftest.py
â”œâ”€â”€ examples/                    # Usage examples
â”‚   â”œâ”€â”€ basic_usage.py
â”‚   â”œâ”€â”€ attack_simulation.py
â”‚   â””â”€â”€ custom_defense.py
â”œâ”€â”€ docs/                        # Documentation
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ ci.yml               # CI/CD pipeline
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â”œâ”€â”€ LICENSE
â””â”€â”€ CONTRIBUTING.md
```

## ğŸ§ª Running Tests

```bash
# Run all tests with coverage
pytest --cov=spartan --cov-report=html

# Run specific test module
pytest tests/test_mplq.py -v

# Run with parallel execution
pytest -n auto
```

## ğŸ“ˆ Benchmarks

```bash
# Run benchmark suite
python -m spartan.benchmarks --model deepseek-r1 --dataset prm800k

# Evaluate attack effectiveness
python -m spartan.evaluate --mode attack --output results/

# Evaluate defense performance
python -m spartan.evaluate --mode defense --output results/
```

## ğŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ“œ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ“– Citation

If you use SPARTAN in your research, please cite:

```bibtex
@article{spartan2025,
  title={SPARTAN: Secure Privacy-Adaptive Reasoning with Test-time Attack Neutralization},
  author={SPARTAN Team},
  journal={arXiv preprint},
  year={2025}
}
```

## ğŸ”— Related Work

- [SoK: Membership Inference Attacks on LLMs](https://arxiv.org/abs/2503.xxxxx) - Best Paper Award, SaTML 2025
- [Process Reward Models for LLM Reasoning](https://arxiv.org/abs/2502.xxxxx) - ICLR 2025 Spotlight
- [Understanding Data Importance in ML Attacks](https://arxiv.org/abs/2502.xxxxx) - NDSS 2025

## ğŸ“§ Contact

For questions and feedback, please open an issue on GitHub or contact the maintainers.

---

**SPARTAN** - Protecting Reasoning LLMs from Privacy Attacks


